{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58fec22b",
   "metadata": {},
   "source": [
    "### Modelo\n",
    "\n",
    "* Definir qué modelo vamos a usar.\n",
    "\n",
    "Paquete de modelos: https://www.statsmodels.org/stable/index.html \n",
    "\n",
    "* Documentación de fórmulas: https://www.statsmodels.org/dev/example_formulas.html  \n",
    "\n",
    "* Fixed effects\n",
    "    * Dummy variable con el user_id para descartar el efecto de eso.\n",
    "\n",
    "* Control variables\n",
    "    * En los papers prueban agregar variables de control de los propios tweets y de los usuarios.\n",
    "\n",
    "* Interaction effect / cross-effect\n",
    "    * Variables independientes que se afectan entre si.\n",
    "    * En este caso podría ser que se consideren las emociones (por ejemplo, resumen de emociones positivas o negativas) o que consideremos los otros engagements.\n",
    "\n",
    "* Multi-collinearity\n",
    "    * ``variance_inflation_factor``. Se calcula para las diferentes variables.\n",
    "    * ``variance_inflation_factor`` expects the presence of a constant in the matrix of explanatory variables. One can use ``add_constant`` from statsmodels to add the required constant to the dataframe before passing its values to the function.\n",
    "    * Si usamos el ``dmatrices`` la constante se agrega.\n",
    "\n",
    "* Mean centered\n",
    "    * Se supone que ayuda. Se le aplica a variables numéricas/continuas.\n",
    "    * Alternativa al log.\n",
    "\n",
    "* Over-disperssion\n",
    "    * cov_type puede ser nonrobust, HC0, HC1, HC2, HC3, HAC\n",
    "    * standard robust sandwich covariances are available with the cov_type option in fit, which allows for heteroscedasticity robust (HC), cluster robust, and heteroscedasticity and autocorrelation robust (HAC) and two panel robust covariance estimators.\n",
    "    * nonrobust assumes there is no overdispersion and underestimates the standard error.\n",
    "    * HC0 se supone que corrige por overdispersion and heteroscedasticity.\n",
    "    * When the response variable is a count, but μ does not equal σ2, the Poisson distribution is not applicable. Over dispersion can be detected by dividing the residual deviance by the degrees of freedom. If this quotient is much greater than one, the negative binomial distribution should be used. There is no hard cut off of “much larger than one”, but a rule of thumb is 1.10 or greater is considered large.\n",
    "    * ``model.pearson_chi2 / model.df_resid`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0dca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ee714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# levantamos todos los dfs que nos interesan para una combinación de nombre\n",
    "\n",
    "def load_dfs(dir_data, name_part):\n",
    "    df_dict = {}\n",
    "\n",
    "#     df_dict['df_all'] = pd.read_pickle(dir_data + 'df_merged__all__' + name_part + '.pickle').sort_values(by='created_at')\n",
    "    df_dict['df_no_covid_2019'] = pd.read_pickle(dir_data + 'df_merged__no_covid_2019__' + name_part + '.pickle').sort_values(by='created_at')\n",
    "    df_dict['df_no_covid'] = pd.read_pickle(dir_data + 'df_merged__no_covid__' + name_part + '.pickle').sort_values(by='created_at')\n",
    "    df_dict['df_pre_covid'] = pd.read_pickle(dir_data + 'df_merged__pre_covid__' + name_part + '.pickle').sort_values(by='created_at')\n",
    "    df_dict['df_during_covid'] = pd.read_pickle(dir_data + 'df_merged__during_covid__' + name_part + '.pickle').sort_values(by='created_at')\n",
    "    df_dict['df_post_covid'] = pd.read_pickle(dir_data + 'df_merged__post_covid__' + name_part + '.pickle').sort_values(by='created_at')\n",
    "\n",
    "    return df_dict\n",
    "\n",
    "dir_data = './df_merged/'\n",
    "name_part = 'normalized_perc_85__tweet_None__df_tweets_social_dimensions_model_simplified' # para facilitar generar los nombres\n",
    "# name_part = 'normalized_perc_85_word_length__tweet_None__df_tweets_social_dimensions_model_simplified'\n",
    "# name_part = 'tweet_None__df_tweets_social_dimensions_model_simplified'\n",
    "\n",
    "df_dict = load_dfs(dir_data, name_part)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1214bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_centered(x):\n",
    "    return x - np.mean(x)\n",
    "    \n",
    "def get_formulas(dependent='favorite_count',cross_effects=['reply_count','retweet_count']):\n",
    "\n",
    "    ten_dims = ['','support', 'knowledge', 'conflict', 'power', 'similarity', 'fun', 'status', 'trust', 'identity', 'romance']\n",
    "    ten_dims_ = ['','support', 'knowledge', 'conflict', 'power', 'similarity', 'fun', 'status', 'trust', 'identity']\n",
    "\n",
    "    tweet_control_log = ['','np.log(word_length)']\n",
    "    tweet_control_expand_ = ['','np.log(word_length)', 'hashtag_count', 'mentions_count', 'url_count']\n",
    "    tweet_control_expand = ['','np.log(word_length)', 'np.log(hashtag_count)', 'np.log(mentions_count)', 'np.log(url_count)']\n",
    "    user_control_log = ['','np.log(followees)', 'np.log(followers)']\n",
    "    user_control = ['','followees', 'followers', 'tweets_before']\n",
    "    \n",
    "    user_control_mean = ['','mean_centered(followees)', 'mean_centered(followers)', 'mean_centered(tweets_before)']\n",
    "    \n",
    "    tweet_control_expand2 = tweet_control_expand + ['mean_centered(tweets_before)']\n",
    "    \n",
    "    dict_formulas = {}\n",
    "\n",
    "    predictor = dependent + ' ~'\n",
    "\n",
    "    dict_formulas['formula_model1'] = predictor + \" C(user_id)\" # dummy para controlar el usuario\n",
    "\n",
    "    dict_formulas['formula_model2'] = dict_formulas['formula_model1'] + ' + '.join(tweet_control_log) # control variables de los tweets\n",
    "    dict_formulas['formula_model2a'] = dict_formulas['formula_model1'] + ' + '.join(tweet_control_expand) # control variables de los tweets\n",
    "    dict_formulas['formula_model2b'] = predictor + ' + '.join(tweet_control_log) # control variables de los tweets\n",
    "    dict_formulas['formula_model2c'] = predictor + ' + '.join(tweet_control_expand) # control variables de los tweets\n",
    "\n",
    "    dict_formulas['formula_model2d'] = dict_formulas['formula_model1'] + ' + '.join(tweet_control_expand2)\n",
    "    dict_formulas['formula_model2e'] = predictor + ' + '.join(tweet_control_expand2)\n",
    "    \n",
    "    \n",
    "    dict_formulas['formula_model3'] = dict_formulas['formula_model2'] + ' + '.join(user_control_log)\n",
    "    dict_formulas['formula_model3a'] = dict_formulas['formula_model2'] + ' + '.join(user_control_mean)\n",
    "    dict_formulas['formula_model3b'] = dict_formulas['formula_model1'] + ' + '.join(user_control_log)\n",
    "    dict_formulas['formula_model3c'] = dict_formulas['formula_model1'] + ' + '.join(user_control_mean)\n",
    "    dict_formulas['formula_model3d'] = dict_formulas['formula_model2b'] + ' + '.join(user_control_log)\n",
    "    dict_formulas['formula_model3e'] = dict_formulas['formula_model2c'] + ' + '.join(user_control_mean)\n",
    "\n",
    "    dict_formulas['formula_model3f'] = dict_formulas['formula_model2'] + ' + '.join(user_control)\n",
    "    dict_formulas['formula_model3g'] = dict_formulas['formula_model1'] + ' + '.join(user_control)\n",
    "    dict_formulas['formula_model3h'] = dict_formulas['formula_model2b'] + ' + '.join(user_control)\n",
    "    dict_formulas['formula_model3i'] = dict_formulas['formula_model2c'] + ' + '.join(user_control)\n",
    "    \n",
    "    dict_formulas['formula_model3j'] = predictor + ' + '.join(user_control_log)\n",
    "    dict_formulas['formula_model3k'] = predictor + ' + '.join(user_control_mean)\n",
    "    dict_formulas['formula_model3l'] = predictor + ' + '.join(user_control)\n",
    "\n",
    "    dict_formulas['formula_model4'] = dict_formulas['formula_model3'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4a'] = dict_formulas['formula_model1'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4b'] = dict_formulas['formula_model2'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4c'] = dict_formulas['formula_model2a'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4d'] = dict_formulas['formula_model3a'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4e'] = dict_formulas['formula_model3b'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4f'] = dict_formulas['formula_model3c'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4g'] = dict_formulas['formula_model3d'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4h'] = dict_formulas['formula_model3e'] + ' + '.join(ten_dims)\n",
    "\n",
    "    dict_formulas['formula_model4i'] = dict_formulas['formula_model3f'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4j'] = dict_formulas['formula_model3g'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4k'] = dict_formulas['formula_model3h'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4l'] = dict_formulas['formula_model3i'] + ' + '.join(ten_dims)\n",
    "    \n",
    "    dict_formulas['formula_model4m'] = dict_formulas['formula_model2c'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4n'] = dict_formulas['formula_model2b'] + ' + '.join(ten_dims)\n",
    "    \n",
    "    dict_formulas['formula_model4o'] = dict_formulas['formula_model3j'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4p'] = dict_formulas['formula_model3k'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4q'] = dict_formulas['formula_model3l'] + ' + '.join(ten_dims)\n",
    "    \n",
    "    dict_formulas['formula_model4m'] = dict_formulas['formula_model2d'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model4n'] = dict_formulas['formula_model2e'] + ' + '.join(ten_dims)\n",
    "    \n",
    "    cc = ' + '+ cross_effects[0] + ' : '\n",
    "    dict_formulas['formula_model5'] = dict_formulas['formula_model4'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model5a'] = dict_formulas['formula_model4a'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model5b'] = dict_formulas['formula_model4b'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model5c'] = dict_formulas['formula_model4c'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model5d'] = dict_formulas['formula_model4d'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model5e'] = dict_formulas['formula_model4e'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model5f'] = dict_formulas['formula_model4f'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model5g'] = dict_formulas['formula_model4g'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model5h'] = dict_formulas['formula_model4h'] + cc.join(ten_dims) \n",
    "\n",
    "    dict_formulas['formula_model5i'] = dict_formulas['formula_model4i'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model5j'] = dict_formulas['formula_model4j'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model5k'] = dict_formulas['formula_model4k'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model5l'] = dict_formulas['formula_model4l'] + cc.join(ten_dims) \n",
    "    \n",
    "    dict_formulas['formula_model5m'] = dict_formulas['formula_model4m'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model5n'] = dict_formulas['formula_model4n'] + cc.join(ten_dims) \n",
    "    \n",
    "    cc = ' + '+ cross_effects[1] + ' : '\n",
    "    dict_formulas['formula_model6'] = dict_formulas['formula_model4'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model6a'] = dict_formulas['formula_model4a'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model6b'] = dict_formulas['formula_model4b'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model6c'] = dict_formulas['formula_model4c'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model6d'] = dict_formulas['formula_model4d'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model6e'] = dict_formulas['formula_model4e'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model6f'] = dict_formulas['formula_model4f'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model6g'] = dict_formulas['formula_model4g'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model6h'] = dict_formulas['formula_model4h'] + cc.join(ten_dims) \n",
    "\n",
    "    dict_formulas['formula_model6i'] = dict_formulas['formula_model4i'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model6j'] = dict_formulas['formula_model4j'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model6k'] = dict_formulas['formula_model4k'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model6l'] = dict_formulas['formula_model4l'] + cc.join(ten_dims) \n",
    "\n",
    "    dict_formulas['formula_model6m'] = dict_formulas['formula_model4m'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model6n'] = dict_formulas['formula_model4n'] + cc.join(ten_dims) \n",
    "    \n",
    "    dict_formulas['formula_model7'] = dict_formulas['formula_model4'] + cc.join(ten_dims_) \n",
    "    dict_formulas['formula_model7a'] = dict_formulas['formula_model4a'] + cc.join(ten_dims_) \n",
    "    dict_formulas['formula_model7b'] = dict_formulas['formula_model4b'] + cc.join(ten_dims_)  \n",
    "    dict_formulas['formula_model7c'] = dict_formulas['formula_model4c'] + cc.join(ten_dims_) \n",
    "    dict_formulas['formula_model7d'] = dict_formulas['formula_model4d'] + cc.join(ten_dims_) \n",
    "    dict_formulas['formula_model7e'] = dict_formulas['formula_model4e'] + cc.join(ten_dims_)  \n",
    "    dict_formulas['formula_model7f'] = dict_formulas['formula_model4f'] + cc.join(ten_dims_)  \n",
    "    dict_formulas['formula_model7g'] = dict_formulas['formula_model4g'] + cc.join(ten_dims_) \n",
    "    dict_formulas['formula_model7h'] = dict_formulas['formula_model4h'] + cc.join(ten_dims_) \n",
    "\n",
    "    dict_formulas['formula_model7i'] = dict_formulas['formula_model4i'] + cc.join(ten_dims_) \n",
    "    dict_formulas['formula_model7j'] = dict_formulas['formula_model4j'] + cc.join(ten_dims_) \n",
    "    dict_formulas['formula_model7k'] = dict_formulas['formula_model4k'] + cc.join(ten_dims_) \n",
    "    dict_formulas['formula_model7l'] = dict_formulas['formula_model4l'] + cc.join(ten_dims_) \n",
    "    \n",
    "    dict_formulas['formula_model7m'] = dict_formulas['formula_model4m'] + cc.join(ten_dims_) \n",
    "    dict_formulas['formula_model7n'] = dict_formulas['formula_model4n'] + cc.join(ten_dims_) \n",
    "    \n",
    "    dict_formulas['formula_model8'] = dict_formulas['formula_model2'] + '+ retweet_count'\n",
    "    dict_formulas['formula_model8a'] = dict_formulas['formula_model2a'] + '+ reply_count'\n",
    "    dict_formulas['formula_model8b'] = dict_formulas['formula_model2'] + '+ retweet_count + reply_count'\n",
    "    dict_formulas['formula_model8c'] = dict_formulas['formula_model2a'] + '+ retweet_count + reply_count'\n",
    "    \n",
    "    dict_formulas['formula_model8d'] = dict_formulas['formula_model8'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model8e'] = dict_formulas['formula_model8a'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model8f'] = dict_formulas['formula_model8b'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model8g'] = dict_formulas['formula_model8c'] + ' + '.join(ten_dims)\n",
    "    \n",
    "    cc = ' + '+ cross_effects[0] + ' : '\n",
    "    dict_formulas['formula_model8h'] = dict_formulas['formula_model8d'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model8i'] = dict_formulas['formula_model8e'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model8j'] = dict_formulas['formula_model8f'] + ' + '.join(ten_dims)\n",
    "    dict_formulas['formula_model8k'] = dict_formulas['formula_model8g'] + ' + '.join(ten_dims)\n",
    "    \n",
    "    cc = ' + '+ cross_effects[1] + ' : '\n",
    "    dict_formulas['formula_model8l'] = dict_formulas['formula_model8h'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model8m'] = dict_formulas['formula_model8i'] + cc.join(ten_dims) \n",
    "    dict_formulas['formula_model8n'] = dict_formulas['formula_model8j'] + cc.join(ten_dims)\n",
    "    dict_formulas['formula_model8o'] = dict_formulas['formula_model8k'] + ' + '.join(ten_dims)      \n",
    "    \n",
    "    return dict_formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dims = df_dict['df_all']\n",
    "\n",
    "model = smf.glm(formula = formula_model2, data=df_dims, family=sm.families.NegativeBinomial()).fit(cov_type='HC0')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02dad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pearson_chi2 / model.df_resid # para chequear overdispersion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f32b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import deque\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def calc_vif(X):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    aa = deque()\n",
    "    for i in tqdm(range(X.shape[1])):\n",
    "        aa.append(variance_inflation_factor(X.values, i)) \n",
    "#     vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    vif['VIF'] = aa\n",
    "\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305aa949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "dep = 'favorite_count'\n",
    "cross = ['reply_count','retweet_count']\n",
    "\n",
    "# dep = 'retweet_count'\n",
    "# cross = ['reply_count','favorite_count']\n",
    "\n",
    "dict_formulas = get_formulas(dep, cross)\n",
    "\n",
    "for ww in df_dict:\n",
    "    print('--------------------',ww)\n",
    "    df_dims = df_dict[ww]\n",
    "    fn = '__ivf__' + name_part + '__' + ww + '.pickle'\n",
    "    print(fn)\n",
    "    dict_ivf = {}\n",
    "        \n",
    "    if os.path.exists(fn):\n",
    "        with open(fn,'rb') as file:\n",
    "            dict_ivf = pickle.load(file)\n",
    "    print(len(dict_ivf))\n",
    "    processed = set(k.split('~')[1] for k in dict_ivf)\n",
    "    for formula,form in dict_formulas.items():\n",
    "\n",
    "#         if form in dict_ivf:\n",
    "#             continue\n",
    "        \n",
    "        if form.split('~')[1] in processed:\n",
    "            continue\n",
    "    \n",
    "        print(formula,'::',form)\n",
    "        y, X = dmatrices(form, df_dims, return_type='dataframe') # esto agrega la constante\n",
    "        df_vif = calc_vif(X)\n",
    "        \n",
    "        dict_ivf[form] = df_vif\n",
    "        with open(fn,'wb') as file:\n",
    "            pickle.dump(dict_ivf,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e276b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlación entre las features, para ver la collinearity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plt.figure(figsize=(10,7))\n",
    "\n",
    "# Generate a mask to onlyshow the bottom triangle\n",
    "mask = np.triu(np.ones_like(df_dims.corr(), dtype=bool))\n",
    "\n",
    "# generate heatmap\n",
    "sns.heatmap(df_dims.corr(), annot=True, mask=mask, vmin=-1, vmax=1)\n",
    "plt.title('Correlation Coefficient Of Predictors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568cc7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e071d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
