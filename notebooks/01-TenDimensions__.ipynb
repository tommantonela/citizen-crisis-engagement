{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d71c25",
   "metadata": {},
   "source": [
    "### TenDimensions of communications\n",
    "\n",
    "Pragmatic meaning of communications.\n",
    "\n",
    "* https://github.com/lajello/tendimensions\n",
    "* Adaptar los modelos de embeddings para extraer los features.\n",
    "* Para cada dimensión hay UN modelo con un embedding determinado.\n",
    "* Los nombres de los embeddings están hardcodeados !\n",
    "    * Ver el formato para cuando lo quiera adaptar con los de español.\n",
    "    * Hay que convertir los embeddings al formato de ``Word2VecKeyedVectors``\n",
    "    * Esto arruina el uso de FastText !! \n",
    "* ``compute_score`` calcula score por el texto completo, ``compute_score_split`` calcula por oración y luego promedia\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be44bf",
   "metadata": {},
   "source": [
    "##### Modelos para español\n",
    "\n",
    "* FastText\n",
    "    * ``wiki-news-300d-1M-subword`` están entrenados con: 1 million word vectors trained with subword infomation on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens)\n",
    "    * Son los modelos originales de Facebook, entrenados con Wikipedia o CommonCrawl.\n",
    "        * Nos quedamos con los de Wikipedia (wiki.es)\n",
    "    * https://github.com/facebookresearch/fastText/blob/master/docs/pretrained-vectors.md\n",
    "    * Pre-procesado: lower case\n",
    "* GloVe\n",
    "    * ``glove.42B.300d`` están entrenados con CommonCrawl\n",
    "    * Stanford no provee modelos en español.\n",
    "    * Usamos los de los chilenos, entrenados con \"Spanish Billion Word Corpus\". Incluye Wikipedia, pero no CommonCrawl, aunque tiene algunos más.\n",
    "    * Tienen un problema con las vocales acentuadas, están TODAS en mayúsculas !!\n",
    "* Word2Vec\n",
    "    * ``GoogleNews-vectors-negative300`` entrenados con Google News, 3 millones de palabras.\n",
    "    * Google no provee modelos en español.\n",
    "    * Usamos los de los chilenos, entrenados con \"Spanish Billion Word Corpus\". Incluye Wikipedia, pero no CommonCrawl, aunque tiene algunos más.\n",
    "    * Pre-procesado: hay upper case, y los most_similar no son los mismos\n",
    "    \n",
    "Los chilenos de la uchile que entrenaron todos: https://github.com/dccuchile/spanish-word-embeddings\n",
    "* No tuvieron mucho cuidado al entrenarlos.\n",
    "* GloVe tiene problemas con los acentos. No todo está en lower case.\n",
    "    * No es simple de arreglar, los nombres própios están en upper case.\n",
    "    * Si el encodding es palabra a palabra, lo que se podría hacer es que si no existe, se busque primero la versión lower y si ninguna está que se asigne el UNK. (setear un parámetro ?) --> Ya lo hacía por defecto el código!\n",
    "* Hacer una combinación? Calcular el valor en case como viene y en lower case? Cómo para tener para comparar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d94f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tendims\n",
    "\n",
    "base_dir = './tendimensions-main/'\n",
    "\n",
    "embeddings_dir = base_dir + 'embeddings/'\n",
    "models_dir = base_dir + 'models/lstm_trained_models/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25277626",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tendims.TenDimensionsClassifier(is_cuda=False, models_dir = models_dir, embeddings_dir = embeddings_dir)\n",
    "model.dimensions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Hello, my name is Mike. I am willing to help you, whatever you need.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0db999",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.compute_score(text, None))\n",
    "model.compute_score_split(text, None) #compute a score for each sentence and returns maximum and average values\n",
    "# (avg, max, min, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = {\n",
    "'knowledge' : [\n",
    "    \"Only a fully trained Jedi Knight, with The Force as his ally, will conquer Vader and his Emperor. If you end your training now, if you choose the quick and easy path, as Vader did, you will become an agent of evil\",\n",
    "    \"Well, in layman's terms, you use a rotating magnetic field to focus a narrow beam of gravitons; these in turn fold space-time consistent with Weyl tensor dynamics until the space-time curvature becomes infinitely large and you have a singularity\",\n",
    "    \"Since positronic signatures have only been known to emanate from androids such as myself, it is logical to theorize that there is an android such as myself on Kolarus III\",\n",
    "],\n",
    "\n",
    "'power' : [\n",
    "    \"Now if you don't want to be the fifth person ever to die in meta-shock from a planar rift, I suggest you get down behind that desk and don't move until we give you the signal\",\n",
    "    \"You can ask any price you want, but you must give me those letters \",\n",
    "    \"Right now you're in no position to ask questions! And your snide remarks...\"\n",
    "],\n",
    "\n",
    "'status' : [\n",
    "    \"I want to thank you, sir, for giving me the opportunity to work\",\n",
    "    \"Frankie, you're a good old man, and you've been loyal to my Father for years...so I hope you can explain what you mean\",\n",
    "    \"And we drink to her, and we all congratulate her on her wonderful accomplishment during this last year...her great success in A Doll's House!\"\n",
    "],\n",
    "\n",
    "'trust' : [\n",
    "    \"I'm trying to tell you – and this is where you have to trust me – but, I think your life might be in real danger\",\n",
    "    \"Mr. Lebowski is prepared to make a generous offer to you to act as courier once we get instructions for the money\",\n",
    "    \"Take the Holy Gospels in your hand and swear to tell the whole truth concerning everything you will be asked\"\n",
    "],\n",
    "\n",
    "'support' : [\n",
    "    \"I'm sorry, I just feel like... I know I shouldn't ask, I just need some kind of help, I just, I have a deadline tomorrow\",\n",
    "    \"Look, Dave, I know that you're sincere and that you're trying to do a competent job, and that you're trying to be helpful, but I can assure the problem is with the AO-units, and with your test gear\",\n",
    "    \"Well... listen, if you need any help, you know, back up, call me, OK?\"\n",
    "],\n",
    "\n",
    "'romance' : [\n",
    "    \"I'm going to marry the woman I love\",\n",
    "    \"If you are truly wild at heart, you'll fight for your dreams... Don’t turn away from love, Sailor \",\n",
    "    \"You admit to me you do not love your fiance?\"\n",
    "],\n",
    "\n",
    "'identity' : [\n",
    "    \"Hey, I know what I'm talkin' about, black women ain't the same as white women \",\n",
    "    \"That's how it was in the old world, Pop, but this is not Sicily\",\n",
    "    \"But, as you are so fond of observing, Doctor, I'm not human\"\n",
    "],\n",
    "\n",
    "'fun' : [\n",
    "    \"It’s just funny...who needs a serial psycho in the woods with a chainsaw when we have ourselves\",\n",
    "    \"I do enjoy playing bingo, if you'd like to join me for a game tomorrow night at church you’re welcome to\",\n",
    "    \"Oh, I'm sure it’s a lot of fun, 'cause the Incas did it, you know, and-and they-they-they were a million laughs\"\n",
    "],\n",
    "\n",
    "'conflict' : [\n",
    "    \"Forgive me for askin', son, and I don’t mean to belabor the obvious, but why is it that you’ve got your head so far up your own ass?\",\n",
    "    \"If you're lying to me you poor excuse for a human being, I'm gonna blow your brains all over this car\",\n",
    "    \"I couldn't give a shit if you believe me or not, and frankly I'm too tired to prove it to you\"\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c15486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rr = []\n",
    "for dim in sentences:\n",
    "    for s in sentences[dim]:\n",
    "        score = model.compute_score_split(s, None)\n",
    "        score['text'] = s\n",
    "        score['all'] =  model.compute_score(s, None)\n",
    "        rr.append(score)\n",
    "        \n",
    "pd.DataFrame(rr).to_pickle(base_dir + 'df_results_en_models_.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49098e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = {\n",
    "'knowledge' : [\n",
    "    \"Only a fully trained Jedi Knight, with The Force as his ally, will conquer Vader and his Emperor. If you finish your training now, if you choose the quick and easy path, as Vader did, you will become an agent of evil.\",\n",
    "    \"Well, in simple terms, you use a rotating magnetic field to focus a narrow beam of gravitons; these, in turn, fold spacetime according to the dynamics of the Weyl tensor until the curvature of spacetime becomes infinitely large and has a singularity\",\n",
    "    \"Since positronic signatures are only known to emanate from androids like me, it stands to reason that there is an android like me on Kolarus III.\",\n",
    "],\n",
    "\n",
    "'power' : [\n",
    "    \"Now, if you don't want to be the fifth person to die in a meta-shock from a flat crack, I suggest you get behind that desk and don't move until we give you the signal.\",\n",
    "    \"You can ask the price you want, but you must give me those cards\",\n",
    "    \"Right now you are in no condition to ask questions! And your sarcastic comments\"\n",
    "],\n",
    "\n",
    "'status' : [\n",
    "    \"I want to thank you sir for giving me the opportunity to work\",\n",
    "    \"Frankie, you are a good old man and have been loyal to my father for years... so I hope you can explain what you mean.\",\n",
    "    \"And we drink to her, and we all congratulate her on her wonderful achievement this past year... her great success in A Doll's House!\"\n",
    "],\n",
    "\n",
    "'trust' : [\n",
    "    \"I'm trying to tell you, and this is where you have to trust me, but I think your life might be in real danger.\",\n",
    "    \"Mr. Lebowski is prepared to make you a generous offer to act as courier once we receive instructions for the money.\",\n",
    "    \"Take in your hand the Holy Gospels and swear to tell the whole truth in everything they ask you.\"\n",
    "],\n",
    "\n",
    "'support' : [\n",
    "    \"I'm sorry, I'm sorry that... I know I shouldn't ask, I just need some kind of help, I just have a deadline tomorrow.\",\n",
    "    \"Look, Dave, I know you're honest and trying to do a competent job and trying to help, but I can assure you that the problem is with the units and your test.\",\n",
    "    \"Well... listen, if you need any help, you know, call me, okay?\"\n",
    "],\n",
    "\n",
    "'romance' : [\n",
    "    \"I'm going to marry the woman I love.\",\n",
    "    \"If you are truly wild at heart, you will fight for your dreams... Don't turn your back on love, Sailor.\",\n",
    "    \"Will you admit to me that you don't love your fiancé?\"\n",
    "],\n",
    "\n",
    "'identity' : [\n",
    "    \"Hey, I know what I'm talking about, black women are not the same as white women.\",\n",
    "    \"That's how it was in the old world, Dad, but this isn't Sicily.\",\n",
    "    \"But as you like to point out, doctor, I'm not human.\"\n",
    "],\n",
    "\n",
    "'fun' : [\n",
    "    \"It's funny... who needs a serial psycho in the woods with a chainsaw when we've got ourselves?\",\n",
    "    \"I enjoy playing bingo, if you'd like to join me for a game tomorrow night at church you're welcome.\",\n",
    "    \"Oh, I'm sure it's a lot of fun, because the Incas did it, you know, and they-they-they were a million laughs.\"\n",
    "],\n",
    "\n",
    "'conflict' : [\n",
    "    \"Forgive me for asking, son, and I don't want to stress the obvious, but why do you have your head so far up your own ass?\",\n",
    "    \"If you're lying to me, you poor excuse for a human being, I'll blow your brains out all over this car.\",\n",
    "    \"I don't give a shit if you believe me or not, and frankly, I'm too tired to show it to you.\"\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rr = []\n",
    "for dim in sentences:\n",
    "    for s in sentences[dim]:\n",
    "        score = model.compute_score_split(s, None)\n",
    "        score['text'] = s\n",
    "        score['all'] =  model.compute_score(s, None)\n",
    "        rr.append(score)\n",
    "        \n",
    "pd.DataFrame(rr).to_pickle(base_dir + 'df_results_en_models_translated.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d93d7",
   "metadata": {},
   "source": [
    "#### Formato Gensim para los modelos\n",
    "\n",
    "Gensim requiere que todo esté en el formato de Word2Vec, lo que significa que pierde un poco de capacidad de análisis cuando los embeddings no se calculan por palabra completa, como es el caso de FastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f082da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors # este es para cargar los vectors ...\n",
    "\n",
    "embeddings_es_dir = './embeddings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2813dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastText\n",
    "file_path = embeddings_es_dir + 'wiki.es/wiki.es.vec' \n",
    "file_path = embeddings_es_dir + 'wiki.es/wiki.es.align.vec' \n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(file_path,binary=False) # estamos levantando el formato texto\n",
    "\n",
    "model.most_similar('perro') # probamos que funcione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94320bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = embeddings_es_dir + 'wiki.es/wiki.es.align.wv' \n",
    "# model.save_word2vec_format(output_file,binary=True) # este no lo deja en el formato que espera el otro !\n",
    "model.save(output_file)\n",
    "\n",
    "model = KeyedVectors.load(output_file,mmap='r')\n",
    "\n",
    "model.most_similar('perro') # son todas lower case !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdfac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec es lo mismo que para FastText\n",
    "\n",
    "file_path = embeddings_es_dir + 'sbw_vectors.bin' \n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(file_path,binary=True) \n",
    "\n",
    "model.most_similar('perro') # probamos que funcione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = embeddings_es_dir + 'sbw_vectors.wv' \n",
    "model.save(output_file)\n",
    "\n",
    "model = KeyedVectors.load(output_file,mmap='r')\n",
    "model.most_similar('perro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3bc091",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = embeddings_es_dir + 'multi.wiki.bpe.vs1000000.d300.w2v.bin'\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(file_path,binary=True) \n",
    "\n",
    "model.most_similar('perro') # probamos que funcione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = embeddings_es_dir + 'multi.wiki.bpe.vs1000000.d300.w2v.wv' \n",
    "model.save(output_file)\n",
    "\n",
    "model = KeyedVectors.load(output_file,mmap='r')\n",
    "model.most_similar('perro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa45d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove \n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "file_path = embeddings_es_dir + 'glove-sbwc.i25.vec' \n",
    "output_file = embeddings_es_dir + 'glove-sbwc.i25.wv'\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(file_path,binary=False) \n",
    "\n",
    "model.save(output_file)\n",
    "\n",
    "model = KeyedVectors.load(output_file,mmap='r')\n",
    "model.most_similar('perro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove -- NO ES REALMENTE MULTILIGUAL?\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "file_path = embeddings_es_dir + 'multilingual_embeddings.es' \n",
    "output_file = embeddings_es_dir + 'glove_multilingual_embeddings.es.wv'\n",
    "\n",
    "glove2word2vec(file_path, output_file) # este es para cuando el archivo no tiene la primera línea de cantidad\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(output_file,binary=False) \n",
    "\n",
    "model.save(output_file)\n",
    "\n",
    "model = KeyedVectors.load(output_file,mmap='r')\n",
    "model.most_similar('perro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32945932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.most_similar('dog') \n",
    "\n",
    "for x in model.key_to_index.keys():\n",
    "    print(x)\n",
    "#     if x.lower() != x:\n",
    "#         print(x,'--',x.lower() in model.key_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05a4fe3",
   "metadata": {},
   "source": [
    "#### Prueba de traducción\n",
    "\n",
    "La intuición es que la semántica de las relaciones no debería cambiar notablemente si están expresadas en español o en inglés, con lo que si probamos las oraciones con los embeddings en inglés y las traducimos para usar los embeddings en español, no debería haber mucha diferencia.\n",
    "\n",
    "Otra opción: Usar modelos de embeddings multilingües.\n",
    "\n",
    "* Hay diferencia para algunas de las dimensiones.\n",
    "    * Trust, por ejemplo, queda siempre arriba, tanto como si correspondiera (de acuerdo a los resultados en inglés), como si no.\n",
    "    * Fun, conflict también sufren algunas diferencias.\n",
    "* Haciendo inglés -> español -> inglés se conservan los scores originales.\n",
    "    * Traducir los tweets sería mucho?\n",
    "    \n",
    "    \n",
    "* Probar qué pasa con oraciones propias en español y traducidas al inglés.\n",
    "    * A ver si hay algún tipo de relación entre los scores.\n",
    "    * A ver si los scores parece que dan como nos interesaría que den.\n",
    "\n",
    "\n",
    "* Modelos crosslingual:\n",
    "    * word2vec: \n",
    "    * gloVe: https://bpemb.h-its.org/multi/ -- No parece ser realmente multi\n",
    "    * FastText: en la misma página que los otros.\n",
    "    * No mejora los resultados :(\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a3e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tendims\n",
    "\n",
    "base_dir = './'\n",
    "\n",
    "embeddings_dir = base_dir + 'embeddings_multi/'\n",
    "models_dir = base_dir + 'models/lstm_trained_models/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe3f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tendims.TenDimensionsClassifier(is_cuda=False, models_dir = models_dir, embeddings_dir = embeddings_dir)\n",
    "model.dimensions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc696cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Hola, mi nombre es Mike. Estoy dispuesto a ayudarte en lo que necesites.'\n",
    "print(model.compute_score(text, None))\n",
    "model.compute_score_split(text, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = {\n",
    "'knowledge' : [\n",
    "    \"Solo un Caballero Jedi completamente entrenado, con La Fuerza como su aliado, conquistará a Vader y su Emperador. Si terminas tu entrenamiento ahora, si eliges el camino rápido y fácil, como hizo Vader, te convertirás en un agente del mal.\",\n",
    "    \"Bueno, en términos sencillos, usas un campo magnético giratorio para enfocar un estrecho haz de gravitones; estos, a su vez, pliegan el espacio-tiempo de acuerdo con la dinámica del tensor de Weyl hasta que la curvatura del espacio-tiempo se vuelve infinitamente grande y tiene una singularidad\",\n",
    "    \"Dado que solo se sabe que las firmas positrónicas emanan de androides como yo, es lógico teorizar que hay un androide como yo en Kolarus III.\",\n",
    "],\n",
    "\n",
    "'power' : [\n",
    "    \"Ahora, si no quieres ser la quinta persona en morir en un meta-shock por una grieta plana, te sugiero que te pongas detrás de ese escritorio y no te muevas hasta que te demos la señal.\",\n",
    "    \"Puedes pedir el precio que quieras, pero debes darme esas cartas\",\n",
    "    \"¡Ahora mismo no estás en condiciones de hacer preguntas! Y tus comentarios sarcásticos\"\n",
    "],\n",
    "\n",
    "'status' : [\n",
    "    \"Quiero agradecerle señor por darme la oportunidad de trabajar\",\n",
    "    \"Frankie, eres un buen anciano y has sido leal a mi padre durante años... así que espero que puedas explicar lo que quieres decir.\",\n",
    "    \"Y brindamos por ella, y todos la felicitamos por su maravilloso logro durante este último año... ¡su gran éxito en Casa de muñecas!\"\n",
    "],\n",
    "\n",
    "'trust' : [\n",
    "    \"Estoy tratando de decírtelo, y aquí es donde tienes que confiar en mí, pero creo que tu vida podría estar en peligro real.\",\n",
    "    \"El Sr. Lebowski está preparado para hacerle una generosa oferta para que actúe como mensajero una vez que recibamos las instrucciones para el dinero.\",\n",
    "    \"Toma en tu mano los Santos Evangelios y jura decir toda la verdad en todo lo que te pregunten.\"\n",
    "],\n",
    "\n",
    "'support' : [\n",
    "    \"Lo siento, siento que... Sé que no debería preguntar, solo necesito algún tipo de ayuda, solo tengo una fecha límite mañana.\",\n",
    "    \"Mira, Dave, sé que eres sincero y que estás tratando de hacer un trabajo competente, y que estás tratando de ayudar, pero te puedo asegurar que el problema está en las unidades y en tu prueba.\",\n",
    "    \"Bueno... escucha, si necesitas ayuda, ya sabes, llámame, ¿de acuerdo?\"\n",
    "],\n",
    "\n",
    "'romance' : [\n",
    "    \"Me voy a casar con la mujer que amo.\",\n",
    "    \"Si eres verdaderamente salvaje de corazón, lucharás por tus sueños... No le des la espalda al amor, Marinero.\",\n",
    "    \"¿Me admites que no amas a tu prometido?\"\n",
    "],\n",
    "\n",
    "'identity' : [\n",
    "    \"Oye, sé de lo que hablo, las mujeres negras no son lo mismo que las mujeres blancas.\",\n",
    "    \"Así era en el viejo mundo, papá, pero esto no es Sicilia.\",\n",
    "    \"Pero, como le gusta observar, doctor, no soy humano.\"\n",
    "],\n",
    "\n",
    "'fun' : [\n",
    "    \"Es divertido... ¿quién necesita un psicópata en serie en el bosque con una motosierra cuando nos tenemos a nosotros mismos?\",\n",
    "    \"Disfruto jugando al bingo, si quieres unirte a mí para un juego mañana por la noche en la iglesia, eres bienvenido.\",\n",
    "    \"Oh, estoy seguro de que es muy divertido, porque los Incas lo hicieron, ya sabes, y ellos-ellos-ellos fueron un millón de risas.\"\n",
    "],\n",
    "\n",
    "'conflict' : [\n",
    "    \"Perdóname por preguntar, hijo, y no quiero insistir en lo obvio, pero ¿por qué tienes la cabeza tan metida en tu propio trasero?\",\n",
    "    \"Si me estás mintiendo, pobre excusa de ser humano, te volaré los sesos por todo este auto.\",\n",
    "    \"Me importa una mierda si me crees o no y, francamente, estoy demasiado cansado para demostrártelo.\"\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2908f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rr = []\n",
    "for dim in sentences:\n",
    "    for s in sentences[dim]:\n",
    "        score = model.compute_score_split(s, None)\n",
    "        score['text'] = s\n",
    "        score['all'] =  model.compute_score(s, None)\n",
    "        rr.append(score)\n",
    "        \n",
    "pd.DataFrame(rr).to_pickle(base_dir + 'df_results_multi.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f18a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_en = pd.read_pickle(base_dir + 'df_results_en_models_.pickle')\n",
    "df_es = pd.read_pickle(base_dir + 'df_results_multi.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_en.merge(df_es,left_index=True,right_index=True,suffixes=('_en', '_es'))\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fce016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "diff = defaultdict(list)\n",
    "\n",
    "dd = ['support', 'knowledge', 'conflict', 'power', 'similarity', 'fun', 'status', 'trust', 'identity', 'romance']\n",
    "for i in range(0,len(df_merge)):\n",
    "    print(df_merge['text_en'].values[i])\n",
    "#     print(df_merge['all_en'].values[i])\n",
    "    print(dict(sorted(df_merge['all_en'].values[i].items(), key=lambda item: -item[1])).keys())\n",
    "#     print(df_merge['all_es'].values[i])\n",
    "    print(dict(sorted(df_merge['all_es'].values[i].items(), key=lambda item: -item[1])).keys())\n",
    "    for d in dd:\n",
    "#         print('  ',d,\"::\",df_merge[d+'_en'].values[i])\n",
    "#         print('  ',d,\"::\",df_merge[d+'_es'].values[i])\n",
    "        print('  ',d,\"::\",round(df_merge[d+'_en'].values[i][0],3),' - ',round(df_merge[d+'_es'].values[i][0],3),' == ',round(df_merge[d+'_en'].values[i][0] - df_merge[d+'_es'].values[i][0],3), \n",
    "#                           df_merge[d+'_en'].values[i][1] - df_merge[d+'_es'].values[i][1], \n",
    "#                           df_merge[d+'_en'].values[i][2] - df_merge[d+'_es'].values[i][2], \n",
    "#                           df_merge[d+'_en'].values[i][3] - df_merge[d+'_es'].values[i][3]\n",
    "             )\n",
    "        diff[d].append(abs(round(df_merge[d+'_en'].values[i][0] - df_merge[d+'_es'].values[i][0],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c218577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in diff.items():\n",
    "    print(k,' :: ',max(v),min(v),' == ',sorted(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6be17d",
   "metadata": {},
   "source": [
    "#### Prueba con algunas traducciones\n",
    "\n",
    "Ya tenemos algunos tweets traducidos, vamos a probar sobre esos tweets obtener los scores, a ver qué parece.\n",
    "Necesita ``df_tweets_db`` para poder ver el texto original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a394927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28195dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "translated = set()\n",
    "for file in tqdm(os.listdir('./')):\n",
    "    if file.startswith('_social_translations_') and not file.startswith('_social_translations_simplified_'):\n",
    "        translated.update(set(pd.read_pickle(file)['tweet_id']))\n",
    "\n",
    "print(len(translated))\n",
    "\n",
    "rr = deque()\n",
    "for file in tqdm(os.listdir('./')):\n",
    "    if file.startswith('_translation'):\n",
    "        with open(file,'rb') as file:\n",
    "            translations = pickle.load(file)\n",
    "        \n",
    "        for k,s in tqdm(translations.items()):\n",
    "            \n",
    "            if k in translated:\n",
    "                continue\n",
    "            \n",
    "            score = model.compute_score_split(s, None)\n",
    "            score['tweet_id'] = k\n",
    "            score['all'] =  model.compute_score(s, None)\n",
    "            rr.append(score)\n",
    "            \n",
    "    if len(rr) >= 2500:\n",
    "        df_scores = pd.DataFrame(rr)\n",
    "        df_scores.to_pickle('_social_translations_' + str(int(datetime.now().timestamp())) + '.pickle')\n",
    "        df_scores = pd.concat([df_scores.reset_index()['tweet_id'],pd.json_normalize(df_scores['all'])],axis=1).set_index('tweet_id')\n",
    "        df_scores.to_pickle('_social_translations_simplified_' + str(int(datetime.now().timestamp())) + '.pickle')\n",
    "        rr.clear()\n",
    "#         break\n",
    "\n",
    "if len(rr) > 0:\n",
    "    df_scores = pd.DataFrame(rr)\n",
    "    df_scores.to_pickle('_social_translations_' + str(int(datetime.now().timestamp())) + '.pickle')\n",
    "    df_scores = pd.concat([df_scores.reset_index()['tweet_id'],pd.json_normalize(df_scores['all'])],axis=1).set_index('tweet_id')\n",
    "    df_scores.to_pickle('_social_translations_simplified_' + str(int(datetime.now().timestamp())) + '.pickle')\n",
    "    rr.clear()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e089e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df_scores_reduced)):\n",
    "    dd = df_scores_reduced.iloc[i].to_dict()\n",
    "    print(' ## ',dd['text'])\n",
    "    del dd['text']\n",
    "    print(dict(sorted(dd.items(), key=lambda item: -item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd01034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
